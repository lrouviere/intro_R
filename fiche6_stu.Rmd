---
title: "Régression avec R"
output: 
  html_notebook:
#    toc: true
#    toc_float: true
---

<style type="text/css">

body{ /* Normal  */
      font-size: 12px;
  }
td {  /* Table  */
  font-size: 12px;
}
h1.title {
  font-size: 48px;
  color: DarkRed;
}
h1 { /* Header 1 */
  font-size: 35px;
  color: DarkBlue;
}
h2 { /* Header 2 */
    font-size: 28px;
  color: DarkBlue;
}
h3 { /* Header 3 */
  font-size: 24px;
  font-family: "Times New Roman", Times, serif;
  color: DarkBlue;
}
code.r{ /* Code block */
    font-size: 12px;
}
pre { /* Code block - determines code spacing between lines */
    font-size: 14px;
}
</style>

```{r message=FALSE, warning=FALSE}
library(tidyverse)
```

Les problèmes de régression et de classification supervisée consitent à expliquer et/ou prédire une sortie $y\in\mathcal Y$ par des entrées $x\in\mathbb R^p$. Il s'agit donc de trouver une fonction 
$$m:\mathbb R^p\to\mathcal Y$$
à partir de données $(X_1,Y_1),\dots,(X_n,Y_n)$.

Ces données sont souvent collectées dans un **data frame** **df** de la forme

$Y$|$X_1$|$X_2$|$\dots$|$X_p$
----|--|-----|-------|----------
$y_1$|$x_{1,1}$|$x_{1,2}$|$\dots$|$x_{1,p}$
$\vdots$|$\vdots$|$\vdots$|$\vdots$|$\vdots$
$\vdots$|$\vdots$|$\vdots$|$\vdots$|$\vdots$
$y_n$|$x_{n,1}$|$x_{n,2}$|$\dots$|$x_{n,p}$

Le protocole pour construire un algorithme de régression sur **R** est toujours le même. Il faut spécifier :

* la méthode (ou l'algorithme)
* la variable à expliquer
* les variables explicatives
* le jeu de données
* les éventuelles options de la méthode considérée.

Par exemple la commande

<center>method(Y~X1+X3,data=df,...)</center>


ajustera le modèle **method** pour expliquer $Y$ par $X_1$ et $X_3$ avec les données dans **df** (les points représentent d'éventuelles options). Voici quelques exemples de méthodes :

fonction R | algorithme | Package | Problème
-----------|-----------|---------|--------
**lm** | modèle linéaire | | Reg 
**glm**| modèle logistique  | |Class
**lda**| analyse discriminante linéaire |MASS |Class
**svm**| Support Vector Machine | e1071 | Class
**knn.reg**|plus proches voisins|FNN| Reg
**knn** | plus proches voisins|class|Class
**rpart**| arbres |rpart| Reg et Class
**glmnet**|ridge et lasso|glmnet|Reg et Class
**gbm**|boosting|gbm|Reg et Class
**randomForest**|forêts aléatoires | randomForest | Reg et Class

**Remark**: pour *glmnet*, on ne peut pas utiliser de formule de la forme **Y~.**. Il faut spécifier une matrice pour les $X$ et un vecteur pour $Y$. La fonction **model.matrix** peut se révéler très utile pour calculer la matrice des $X$.

Puisqu'il existe un grand nombre d'algorithmes pour répondre à un même problème de régression, il est important de définir des critères de performance afin de les comparer. Ces critères sont généralement inconnus et doivent être estimés à l'aide de procédure de type **apprentissage/validation** ou **validation croisée**. On a souvent besoin d'utiliser la fonction **predict** pour calculer ces critères. Cette fonction est une **fonction générique** : on peut utiliser **predict** pour une régression linéaire, logistique, un arbre, une forêt aléatoire... Pour obtenir l'aide de cette fonction pour

* la régression linéaire : taper **help(predict.lm)**
* la régression logisitque : taper **help(predict.glm)**
* les régressions pénalisées : taper **help(predict.glmnet)**
* les arbres : taper **help(predict.rpart)**
* les forêts aléatoires : taper **help(predict.randomForest)**
* ...


Dans la suite on suppose que $\mathcal Y=\mathbb R$ et on considère le modèle de régression
$$Y=m(X)+\varepsilon.$$
La performance d'un estimateur $\widehat{m}$ de $m$ sera mesurée par son erreur quadratique de prédiction :
$$E[(Y-\widehat m(X))^2].$$

## Exercice 1 (modèle linéaire, lm et predict)

On considère le modèle de régression linéaire
$$Y=\beta_0+\beta_1X_1+\dots+\beta_pX_p+\varepsilon$$
où $X_1,\dots,X_p$ sont les variables explicatives, $Y$ la variable à expliquer et $\varepsilon$ le terme d'erreur. On fixe $p=5$ et on considère les données suivantes :


```{r}
n <- 1000
p <- 5
set.seed(1234)
X.mat <- matrix(rnorm(n*p),ncol=p)
eps <- rnorm(n,mean = 0,sd=0.5)
df <- data.frame(X.mat,eps)
df <- df %>% mutate(Y=X1+X2+X3+X4+X5+eps) %>% select(-eps)
```

1. Construire un modèle linaire permettant d'expliquer $Y$ par $X_1,\dots,X_5$ (utiliser la fonction **lm**) et afficher les estimateurs  de $\beta_0,\dots,\beta_5$ (on pourra utiliser la fonction **coef** ou **summary**).



2. On considère le jeu de données test suivant.
```{r}
m <- 500
p <- 5
set.seed(12345)
X.mat <- matrix(rnorm(m*p),ncol=5)
eps <- rnorm(m,mean = 0,sd=0.5)
df.test <- data.frame(X.mat,eps)
df.test <- df.test %>% mutate(Y=X1+X2+X3+X4+X5+eps) %>% select(-eps)
```

Calculer, pour chaque individu de ce nouveau jeu de données, les prédictions faites par le modèle de la question précédente (utiliser la fonction  **predict** avec l'option *newdata*).

```{r}
pred <- predict(...)
```

3. Créer un nouveau data-frame qui contiennent les valeurs prédites $\widehat y_i$ à la question précedente sur une colonne et les valeurs observées $y_i$ du jeu de données **df.test** sur une autre colonne.



4. A l'aide du verbe **summarize**, calculer l'erreur quadratique moyenne (estimée) du modèle linéaire :
$$\frac{1}{m}\sum_{i\in test}(\widehat y_i-y_i)^2.$$



## Exercice 2 (sélection de variables)

On considère les données suivantes

```{r}
n <- 1000
p <- 105
set.seed(1234)
X.mat <- matrix(rnorm(n*p),ncol=p)
eps <- rnorm(n,mean = 0,sd=0.5)
df <- data.frame(X.mat,eps)
df <- df %>% mutate(Y=X1+X2+X3+X4+X5+eps) %>% select(-eps)
```
issues du modèle
$$Y=\beta_0+\beta_1X_1+\dots+\beta_pX_p+\varepsilon$$
avec $p=105$. On remarquera que seules les variables $X_1,\dots,X_5$ sont explicatives.

1. Ajuster un modèle linéaire (fonction **lm**) sur *df* et afficher les estimateurs de $\beta_0,\dots,\beta_{105}$.


2. On propose d'utiliser une procédure de sélection de variables **backward** à partir du critère **BIC**. Effectuer cette procédure à l'aide de la fonction **step** (on pourra utiliser les options **direction="backward"** et **k=log(1000)**). On appelera ce modèle **mod.step**.

```{r}
mod.step <- step(...)
summary(mod.step)
```

On a selectionné un modèle avec 8 variables : les 5 explicatives et 3 variables de bruit.

3. Calculer les erreurs quadratiques de prévision
$$\frac{1}{m}\sum_{i\in test}(\widehat y_i-y_i)^2$$
des deux modèles en utilisant le jeu de données test suivant.

```{r}
m <- 300
p <- 105
set.seed(12345)
X.mat <- matrix(rnorm(m*p),ncol=p)
eps <- rnorm(m,mean = 0,sd=0.5)
df.test <- data.frame(X.mat,eps)
df.test <- df.test %>% mutate(Y=X1+X2+X3+X4+X5+eps) %>% select(-eps)
```


## Exercice 3 (régression logistique et arbre)

On considère le jeu de données **spam** disponible ici

```{r message=FALSE, warning=FALSE}
library(kernlab)
data(spam)
```

Le problème est d'expliquer la variable **type** (un email est un spam ou non) par les 57 autres variables.

1. Séparer les données en un échantillon d'apprentissage **dapp** de taille 3000 et un échantillon test **dtest** de taille 1601. On pourra utiliser la fonction **sample**.

```{r}
perm <- sample(...)
dapp <- spam[perm,]
dtest <- spam[-perm,]
```

2. Construire un modèle logistique permettant de répondre au problème en utilisant uniquement les données d'apprentissage. On utilisera la fonction **glm** avec l'option **family="binomial"**.

```{r}
m.logit <- glm(...)
```

3. A l'aide de la fonction **step**, effectuer une sélection bacwkard (ça peut prendre quelques minutes).

```{r message=FALSE, warning=FALSE}
m.step <- step(...)
```

4. A l'aide de la fonction **rpart** du package **rpart**, construire un abre de régression (toujours sur les données d'apprentissage) pour répondre au problème.

```{r}
library(rpart)
arbre <- rpart(...)
```

5. Visualiser l'arbre construit à l'aide des fonctions **rpart.plot** et **visTree** des packages **rpart.plot** et **visNetwork**

```{r}
library(rpart.plot)
rpart.plot(arbre)
library(visNetwork)
visTree(arbre)
```

6. Pour les 3 modèles construits (logistique, backward et arbre) calculer les prédictions de la variable **type** pour les individus de l'échantillon **dtest**. On pourra regrouper ces prévisions dans un data-frame à 3 colonnes.



7. Ajouter au data-frame précédent une colonne où on mettra les valeurs observées de la variable à expliquer.


8. A l'aide de **summarize_at** calculer les erreurs de classification des 3 modèles.


9. Représenter les courbes **ROC** et calculer les **AUC**. On pourra consulter les pages 346 et 347 du livre **"R pour la statistique et la science des données"**



